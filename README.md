
# Health Data Pipeline & Analytics Platform

> **Desafio T√©cnico** > Solu√ß√£o Full Stack para Engenharia de Dados na Sa√∫de Suplementar.

Este reposit√≥rio cont√©m uma solu√ß√£o completa para o ciclo de vida de dados da ANS (Ag√™ncia Nacional de Sa√∫de Suplementar), abrangendo desde a extra√ß√£o automatizada (ETL) at√© a visualiza√ß√£o em dashboard web.

---

## üóÇÔ∏è Estrutura Modular do Projeto

O projeto foi arquitetado em 4 m√≥dulos independentes, facilitando a manuten√ß√£o, escalabilidade e separa√ß√£o de responsabilidades:

```text
/
‚îú‚îÄ‚îÄ 01_etl_ans/           # [Java 21] Pipeline de Extra√ß√£o, Transforma√ß√£o e Carga (ETL)
‚îú‚îÄ‚îÄ 02_validacao_dados/   # [Python] Scripts de valida√ß√£o de CNPJ e enriquecimento
‚îú‚îÄ‚îÄ 03_analise_sql/       # [SQL] Modelagem Dimensional e Queries Anal√≠ticas
‚îú‚îÄ‚îÄ 04_plataforma_web/    # [Vue.js + Python] Dashboard e API REST
‚îî‚îÄ‚îÄ data/                 # Data Lake local (Raw e Processed)

```

---

## üöÄ M√≥dulo 1: ETL de Demonstra√ß√µes Cont√°beis (Java)

**Localiza√ß√£o:** [`./01_etl_ans`](https://www.google.com/search?q=./01_etl_ans)

**Tecnologia:** Java 21 (LTS), Maven, JUnit 5.

Este m√≥dulo √© o cora√ß√£o da ingest√£o de dados. Ele automatiza a coleta de demonstra√ß√µes cont√°beis trimestrais, resolve inconsist√™ncias de formato e consolida os dados para an√°lise posterior.

### üõ†Ô∏è Arquitetura da Solu√ß√£o

O pipeline executa 4 est√°gios sequenciais e at√¥micos:

1. **Crawler Inteligente (`CrawlerANS`):**
* Varre recursivamente o servidor FTP da ANS.
* Identifica dinamicamente os 3 trimestres mais recentes dispon√≠veis (via Regex).
* Realiza o download resiliente, detectando automaticamente se o alvo √© um arquivo `.zip` direto ou uma estrutura de diret√≥rios.


2. **Descompacta√ß√£o Segura (`Descompactador`):**
* Extrai os arquivos CSV para uma √°rea de *staging* tempor√°ria.
* For√ßa o encoding **ISO-8859-1** para garantir a leitura correta de caracteres acentuados (padr√£o legado governamental).


3. **Parsing & Normaliza√ß√£o (`LeitorCSV`):**
* Detecta automaticamente varia√ß√µes de schema (ex: colunas `VL_SALDO_FINAL` vs `Valor`).
* Converte formata√ß√£o monet√°ria brasileira (PT-BR) para `BigDecimal`.
* Enriquece os dados extraindo Ano e Trimestre diretamente do nome do arquivo (Fonte de verdade).


4. **Consolida√ß√£o (`Consolidador`):**
* Aplica regras de neg√≥cio (filtragem de dados inconsistentes).
* Gera o arquivo final unificado `consolidado_despesas.csv` e o compacta em ZIP.



---

## üß† Decis√µes T√©cnicas e Trade-offs (An√°lise Cr√≠tica)

Conforme os crit√©rios de avalia√ß√£o do desafio, abaixo est√£o as justificativas para as decis√µes de engenharia adotadas:

### 1. Estrat√©gia de Processamento: *In-Memory* vs *Streaming*

* **Decis√£o:** Processamento em Mem√≥ria (Listas).
* **Contexto:** O volume de dados dos √∫ltimos 3 trimestres (~2.1 milh√µes de registros) ocupa aproximadamente 600MB na Heap da JVM.
* **Justificativa:** Optou-se pela abordagem *In-Memory* para reduzir a complexidade acidental do c√≥digo (*KISS - Keep It Simple*) e permitir opera√ß√µes r√°pidas sem o overhead de I/O constante.
* **Performance:** O tempo total de execu√ß√£o (~11 segundos) valida que a mem√≥ria n√£o √© um gargalo para este volume de dados. Caso o requisito mudasse para "Hist√≥rico de 10 anos", a arquitetura seria refatorada para *Streaming*.

### 2. Tratamento de Inconsist√™ncias (Qualidade de Dados)

* **Remo√ß√£o de Valores <= 0:** Em an√°lises de despesas assistenciais para BI, valores negativos (geralmente estornos cont√°beis) distorcem as m√©tricas de agrega√ß√£o. A limpeza removeu cerca de 40% de "ru√≠do" do dataset, aumentando a precis√£o anal√≠tica.
* **Datas via Metadados:** As colunas de data dentro dos arquivos CSV originais apresentaram instabilidade de formato. A extra√ß√£o do per√≠odo via Regex no nome do arquivo (ex: `1T2025.csv`) garantiu consist√™ncia temporal absoluta.

### 3. Stack Tecnol√≥gica (Java 21)

* A escolha do **Java 21** permitiu o uso de *Text Blocks* e m√©todos modernos de Cole√ß√µes (`List.getFirst()`), resultando em um c√≥digo mais limpo, leg√≠vel e seguro comparado a vers√µes legadas (Java 8/11).

---

## ‚úÖ Diferenciais Implementados

Este projeto implementa requisitos de **Qualidade de Software** listados como diferenciais no descritivo da vaga:

* **üß™ Testes Automatizados:**
* Implementa√ß√£o de testes unit√°rios com **JUnit 5** e **AssertJ**.
* Cobertura cr√≠tica da classe `LeitorCSV`, validando: convers√£o monet√°ria, encoding ISO-8859-1 e extra√ß√£o de datas.


* **‚ö° Performance e Resili√™ncia:**
* Uso de `User-Agent` rotativo no Crawler para evitar bloqueios (HTTP 403).
* Parsing otimizado com `Apache Commons CSV`.


* **üèóÔ∏è Organiza√ß√£o e Boas Pr√°ticas:**
* Separa√ß√£o clara de responsabilidades (SRP) em pacotes (`etl`, `model`, `parser`).
* Logs profissionais (`java.util.logging`) para rastreabilidade de execu√ß√£o.



---

## ‚ñ∂Ô∏è Como Executar

### Pr√©-requisitos

* Java JDK 21+
* Maven 3.8+

### Passo a Passo

1. Acesse o diret√≥rio do m√≥dulo:
```bash
cd 01_etl_ans

```


2. **Execute os testes unit√°rios** (Para validar a integridade do c√≥digo):
```bash
mvn test

```


3. **Execute o Pipeline ETL** (Para gerar os dados):
```bash
mvn clean install
java -cp target/classes:target/dependency/* br.com.seu.Main

```



**Resultado:** O arquivo processado final estar√° dispon√≠vel em:
`data/processed/consolidado_despesas.zip`

---


## üß™ M√≥dulo 2: Valida√ß√£o e Enriquecimento de Dados (Java)

**Localiza√ß√£o:** [`./02_validacao_dados`](./02_validacao_dados)

**Tecnologia:** Java 21 (LTS), Apache Commons CSV, JUnit 5.

Este m√≥dulo atua como a camada de *Quality Assurance* (QA) e Enriquecimento. Ele consome os dados brutos gerados pelo ETL, aplica valida√ß√µes matem√°ticas (CNPJ), cruza com bases externas da ANS e gera m√©tricas estat√≠sticas para suporte √† decis√£o.

### üõ†Ô∏è Arquitetura da Solu√ß√£o

O pipeline executa 4 est√°gios sequenciais e at√¥micos:

1. **Coleta de Refer√™ncia (`BaixadorCadastro`):**
    * Conecta-se √† API de Dados Abertos da ANS para baixar o cadastro atualizado de operadoras.
    * Implementa um cliente HTTP resiliente (simulando *Browser User-Agent*) para evitar bloqueios de seguran√ßa (Erro 403).

2. **Parsing Resiliente (`CsvUtil`):**
    * L√™ arquivos CSV ignorando BOM (*Byte Order Mark*) e varia√ß√µes de encoding (UTF-8 vs ISO-8859-1).
    * Aplica sanitiza√ß√£o de dados: remo√ß√£o de caracteres n√£o num√©ricos e normaliza√ß√£o de nomes.

3. **Valida√ß√£o Matem√°tica (`ValidadorCNPJ`):**
    * Implementa o algoritmo **M√≥dulo 11** para verificar a autenticidade dos d√≠gitos verificadores dos CNPJs.
    * Classifica os registros sem descart√°-los (estrat√©gia de *Soft Validation*).

4. **Enriquecimento & Analytics (`ProcessadorJoin`):**
    * Realiza o cruzamento de dados (*Join*) entre as Despesas Financeiras e o Cadastro da ANS.
    * Calcula m√©tricas agregadas por operadora: Soma Total, M√©dia Trimestral e **Desvio Padr√£o Amostral**.

---

## üß† Decis√µes T√©cnicas e Trade-offs (An√°lise Cr√≠tica)

Conforme os crit√©rios de avalia√ß√£o, abaixo est√£o as justificativas para as decis√µes de engenharia adotadas neste m√≥dulo:

### 1. Estrat√©gia de Join: *Hash Map* vs *Nested Loop*

* **Decis√£o:** *In-Memory Hash Join*.
* **Contexto:** O cadastro de operadoras possui apenas ~1.200 registros, cabendo confortavelmente na mem√≥ria.
* **Justificativa:** Carregar o cadastro em um `HashMap<String, Operadora>` permite acesso com complexidade **O(1)**. Isso torna o cruzamento com as milhares de linhas de despesas exponencialmente mais r√°pido do que uma busca linear ou la√ßos aninhados (O(N*M)).

### 2. Valida√ß√£o de Dados: *Flagging* vs *Dropping*

* **Decis√£o:** *Flagging* (Marcar com `CNPJ_Valido = false`).
* **Contexto:** Registros financeiros cont√™m valores monet√°rios que comp√µem o balan√ßo total.
* **Justificativa:** Em sistemas financeiros, descartar uma linha devido a um erro de digita√ß√£o no cadastro (typo) altera o montante final ("furo no caixa"). A estrat√©gia de marcar o registro permite auditoria posterior sem perda de integridade cont√°bil.

### 3. Resolu√ß√£o de Chaves (An√°lise de Qualidade)

* **Problema:** O uso inicial do **CNPJ** como chave de liga√ß√£o resultou em 100% de falha (0 matches) devido a inconsist√™ncias de formata√ß√£o na fonte.
* **Solu√ß√£o:** Altera√ß√£o da chave prim√°ria de cruzamento para o **N√∫mero de Registro na ANS**.
* **Resultado:** A taxa de sucesso subiu para **~99%**, restando apenas operadoras inativas ou canceladas, que foram tratadas como "NAO ENCONTRADA" para manter a rastreabilidade.

---

## ‚úÖ Diferenciais Implementados

* **üß™ Testes Unit√°rios Matem√°ticos:**
    * Cobertura de testes na classe `ValidadorCNPJ` garantindo a precis√£o do algoritmo M√≥dulo 11.
    * Valida√ß√£o de casos de borda (CNPJs com d√≠gitos iguais, nulos ou formato incorreto).

* **üìä Estat√≠stica Descritiva:**
    * Implementa√ß√£o manual do c√°lculo de **Desvio Padr√£o** (`EstatisticaService`) para identificar volatilidade nas despesas, sem depend√™ncia de bibliotecas pesadas de Data Science.

---

## ‚ñ∂Ô∏è Como Executar

### Passo a Passo

1. Acesse o diret√≥rio do m√≥dulo:
```bash
cd 02_validacao_dados

```

2. **Execute os testes unit√°rios** (Para validar a matem√°tica do CNPJ):
```bash
mvn test

```


3. **Execute o Processamento**:
```bash
mvn clean install
java -cp target/classes:target/dependency/* br.com.seu.Main

```



**Resultado:** O arquivo enriquecido final estar√° dispon√≠vel em:
`data/processed/despesas_agregadas.csv`


**Autor:** Nicolas Harnisch


# Health Data Pipeline & Analytics Platform

> **Desafio T√©cnico** > Solu√ß√£o Full Stack para Engenharia de Dados na Sa√∫de Suplementar.

Este reposit√≥rio cont√©m uma solu√ß√£o completa para o ciclo de vida de dados da ANS (Ag√™ncia Nacional de Sa√∫de Suplementar), abrangendo desde a extra√ß√£o automatizada (ETL) at√© a visualiza√ß√£o em dashboard web.

---

## üóÇÔ∏è Estrutura Modular do Projeto

O projeto foi arquitetado em 4 m√≥dulos independentes, facilitando a manuten√ß√£o, escalabilidade e separa√ß√£o de responsabilidades:

```text
/
‚îú‚îÄ‚îÄ 01_etl_ans/           # [Java 21] Pipeline de Extra√ß√£o, Transforma√ß√£o e Carga (ETL)
‚îú‚îÄ‚îÄ 02_validacao_dados/   # [Python] Scripts de valida√ß√£o de CNPJ e enriquecimento
‚îú‚îÄ‚îÄ 03_analise_sql/       # [SQL] Modelagem Dimensional e Queries Anal√≠ticas
‚îú‚îÄ‚îÄ 04_plataforma_web/    # [Vue.js + Python] Dashboard e API REST
‚îî‚îÄ‚îÄ data/                 # Data Lake local (Raw e Processed)

```

---

## üöÄ M√≥dulo 1: ETL de Demonstra√ß√µes Cont√°beis (Java)

**Localiza√ß√£o:** [`./01_etl_ans`](https://www.google.com/search?q=./01_etl_ans)

**Tecnologia:** Java 21 (LTS), Maven, JUnit 5.

Este m√≥dulo √© o cora√ß√£o da ingest√£o de dados. Ele automatiza a coleta de demonstra√ß√µes cont√°beis trimestrais, resolve inconsist√™ncias de formato e consolida os dados para an√°lise posterior.

### üõ†Ô∏è Arquitetura da Solu√ß√£o

O pipeline executa 4 est√°gios sequenciais e at√¥micos:

1. **Crawler Inteligente (`CrawlerANS`):**
* Varre recursivamente o servidor FTP da ANS.
* Identifica dinamicamente os 3 trimestres mais recentes dispon√≠veis (via Regex).
* Realiza o download resiliente, detectando automaticamente se o alvo √© um arquivo `.zip` direto ou uma estrutura de diret√≥rios.


2. **Descompacta√ß√£o Segura (`Descompactador`):**
* Extrai os arquivos CSV para uma √°rea de *staging* tempor√°ria.
* For√ßa o encoding **ISO-8859-1** para garantir a leitura correta de caracteres acentuados (padr√£o legado governamental).


3. **Parsing & Normaliza√ß√£o (`LeitorCSV`):**
* Detecta automaticamente varia√ß√µes de schema (ex: colunas `VL_SALDO_FINAL` vs `Valor`).
* Converte formata√ß√£o monet√°ria brasileira (PT-BR) para `BigDecimal`.
* Enriquece os dados extraindo Ano e Trimestre diretamente do nome do arquivo (Fonte de verdade).


4. **Consolida√ß√£o (`Consolidador`):**
* Aplica regras de neg√≥cio (filtragem de dados inconsistentes).
* Gera o arquivo final unificado `consolidado_despesas.csv` e o compacta em ZIP.



---

## üß† Decis√µes T√©cnicas e Trade-offs (An√°lise Cr√≠tica)

Conforme os crit√©rios de avalia√ß√£o do desafio, abaixo est√£o as justificativas para as decis√µes de engenharia adotadas:

### 1. Estrat√©gia de Processamento: *In-Memory* vs *Streaming*

* **Decis√£o:** Processamento em Mem√≥ria (Listas).
* **Contexto:** O volume de dados dos √∫ltimos 3 trimestres (~2.1 milh√µes de registros) ocupa aproximadamente 600MB na Heap da JVM.
* **Justificativa:** Optou-se pela abordagem *In-Memory* para reduzir a complexidade acidental do c√≥digo (*KISS - Keep It Simple*) e permitir opera√ß√µes r√°pidas sem o overhead de I/O constante.
* **Performance:** O tempo total de execu√ß√£o (~11 segundos) valida que a mem√≥ria n√£o √© um gargalo para este volume de dados. Caso o requisito mudasse para "Hist√≥rico de 10 anos", a arquitetura seria refatorada para *Streaming*.

### 2. Tratamento de Inconsist√™ncias (Qualidade de Dados)

* **Remo√ß√£o de Valores <= 0:** Em an√°lises de despesas assistenciais para BI, valores negativos (geralmente estornos cont√°beis) distorcem as m√©tricas de agrega√ß√£o. A limpeza removeu cerca de 40% de "ru√≠do" do dataset, aumentando a precis√£o anal√≠tica.
* **Datas via Metadados:** As colunas de data dentro dos arquivos CSV originais apresentaram instabilidade de formato. A extra√ß√£o do per√≠odo via Regex no nome do arquivo (ex: `1T2025.csv`) garantiu consist√™ncia temporal absoluta.

### 3. Stack Tecnol√≥gica (Java 21)

* A escolha do **Java 21** permitiu o uso de *Text Blocks* e m√©todos modernos de Cole√ß√µes (`List.getFirst()`), resultando em um c√≥digo mais limpo, leg√≠vel e seguro comparado a vers√µes legadas (Java 8/11).

---

## ‚úÖ Diferenciais Implementados

Este projeto implementa requisitos de **Qualidade de Software** listados como diferenciais no descritivo da vaga:

* **üß™ Testes Automatizados:**
* Implementa√ß√£o de testes unit√°rios com **JUnit 5** e **AssertJ**.
* Cobertura cr√≠tica da classe `LeitorCSV`, validando: convers√£o monet√°ria, encoding ISO-8859-1 e extra√ß√£o de datas.


* **‚ö° Performance e Resili√™ncia:**
* Uso de `User-Agent` rotativo no Crawler para evitar bloqueios (HTTP 403).
* Parsing otimizado com `Apache Commons CSV`.


* **üèóÔ∏è Organiza√ß√£o e Boas Pr√°ticas:**
* Separa√ß√£o clara de responsabilidades (SRP) em pacotes (`etl`, `model`, `parser`).
* Logs profissionais (`java.util.logging`) para rastreabilidade de execu√ß√£o.



---

## ‚ñ∂Ô∏è Como Executar

### Pr√©-requisitos

* Java JDK 21+
* Maven 3.8+

### Passo a Passo

1. Acesse o diret√≥rio do m√≥dulo:
```bash
cd 01_etl_ans

```


2. **Execute os testes unit√°rios** (Para validar a integridade do c√≥digo):
```bash
mvn test

```


3. **Execute o Pipeline ETL** (Para gerar os dados):
```bash
mvn clean install
java -cp target/classes:target/dependency/* br.com.seu.Main

```



**Resultado:** O arquivo processado final estar√° dispon√≠vel em:
`data/processed/consolidado_despesas.zip`

---


## üß™ M√≥dulo 2: Valida√ß√£o e Enriquecimento de Dados (Java)

**Localiza√ß√£o:** [`./02_validacao_dados`](./02_validacao_dados)

**Tecnologia:** Java 21 (LTS), Apache Commons CSV, JUnit 5.

Este m√≥dulo atua como a camada de *Quality Assurance* (QA) e Enriquecimento. Ele consome os dados brutos gerados pelo ETL, aplica valida√ß√µes matem√°ticas (CNPJ), cruza com bases externas da ANS e gera m√©tricas estat√≠sticas para suporte √† decis√£o.

### üõ†Ô∏è Arquitetura da Solu√ß√£o

O pipeline executa 4 est√°gios sequenciais e at√¥micos:

1. **Coleta de Refer√™ncia (`BaixadorCadastro`):**
    * Conecta-se √† API de Dados Abertos da ANS para baixar o cadastro atualizado de operadoras.
    * Implementa um cliente HTTP resiliente (simulando *Browser User-Agent*) para evitar bloqueios de seguran√ßa (Erro 403).

2. **Parsing Resiliente (`CsvUtil`):**
    * L√™ arquivos CSV ignorando BOM (*Byte Order Mark*) e varia√ß√µes de encoding (UTF-8 vs ISO-8859-1).
    * Aplica sanitiza√ß√£o de dados: remo√ß√£o de caracteres n√£o num√©ricos e normaliza√ß√£o de nomes.

3. **Valida√ß√£o Matem√°tica (`ValidadorCNPJ`):**
    * Implementa o algoritmo **M√≥dulo 11** para verificar a autenticidade dos d√≠gitos verificadores dos CNPJs.
    * Classifica os registros sem descart√°-los (estrat√©gia de *Soft Validation*).

4. **Enriquecimento & Analytics (`ProcessadorJoin`):**
    * Realiza o cruzamento de dados (*Join*) entre as Despesas Financeiras e o Cadastro da ANS.
    * Calcula m√©tricas agregadas por operadora: Soma Total, M√©dia Trimestral e **Desvio Padr√£o Amostral**.

---

## üß† Decis√µes T√©cnicas e Trade-offs (An√°lise Cr√≠tica)

Conforme os crit√©rios de avalia√ß√£o, abaixo est√£o as justificativas para as decis√µes de engenharia adotadas neste m√≥dulo:

### 1. Estrat√©gia de Join: *Hash Map* vs *Nested Loop*

* **Decis√£o:** *In-Memory Hash Join*.
* **Contexto:** O cadastro de operadoras possui apenas ~1.200 registros, cabendo confortavelmente na mem√≥ria.
* **Justificativa:** Carregar o cadastro em um `HashMap<String, Operadora>` permite acesso com complexidade **O(1)**. Isso torna o cruzamento com as milhares de linhas de despesas exponencialmente mais r√°pido do que uma busca linear ou la√ßos aninhados (O(N*M)).

### 2. Valida√ß√£o de Dados: *Flagging* vs *Dropping*

* **Decis√£o:** *Flagging* (Marcar com `CNPJ_Valido = false`).
* **Contexto:** Registros financeiros cont√™m valores monet√°rios que comp√µem o balan√ßo total.
* **Justificativa:** Em sistemas financeiros, descartar uma linha devido a um erro de digita√ß√£o no cadastro (typo) altera o montante final ("furo no caixa"). A estrat√©gia de marcar o registro permite auditoria posterior sem perda de integridade cont√°bil.

### 3. Resolu√ß√£o de Chaves (An√°lise de Qualidade)

* **Problema:** O uso inicial do **CNPJ** como chave de liga√ß√£o resultou em 100% de falha (0 matches) devido a inconsist√™ncias de formata√ß√£o na fonte.
* **Solu√ß√£o:** Altera√ß√£o da chave prim√°ria de cruzamento para o **N√∫mero de Registro na ANS**.
* **Resultado:** A taxa de sucesso subiu para **~99%**, restando apenas operadoras inativas ou canceladas, que foram tratadas como "NAO ENCONTRADA" para manter a rastreabilidade.

---

## ‚úÖ Diferenciais Implementados

* **üß™ Testes Unit√°rios Matem√°ticos:**
    * Cobertura de testes na classe `ValidadorCNPJ` garantindo a precis√£o do algoritmo M√≥dulo 11.
    * Valida√ß√£o de casos de borda (CNPJs com d√≠gitos iguais, nulos ou formato incorreto).

* **üìä Estat√≠stica Descritiva:**
    * Implementa√ß√£o manual do c√°lculo de **Desvio Padr√£o** (`EstatisticaService`) para identificar volatilidade nas despesas, sem depend√™ncia de bibliotecas pesadas de Data Science.

---

## ‚ñ∂Ô∏è Como Executar

### Passo a Passo

1. Acesse o diret√≥rio do m√≥dulo:
```bash
cd 02_validacao_dados

```

2. **Execute os testes unit√°rios** (Para validar a matem√°tica do CNPJ):
```bash
mvn test

```


3. **Execute o Processamento**:
```bash
mvn clean install
java -cp target/classes:target/dependency/* br.com.seu.Main

```



**Resultado:** O arquivo enriquecido final estar√° dispon√≠vel em:
`data/processed/despesas_agregadas.csv`


**Autor:** Nicolas Harnisch

